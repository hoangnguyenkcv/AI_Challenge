{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "import os\n",
    "import warnings\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation, Lambda, Permute, Reshape\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "import tensorflow as tf\n",
    "os.environ['PYTHONASHSEED']= '0'\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import  BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import theano\n",
    "import  matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import itertools\n",
    "from numpy import*\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "import random as rn\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting  the  seed for nummy_gennerated random numbers\n",
    "np.random.seed(47)\n",
    "#seting the seed for python random numbers\n",
    "rn.seed(122)\n",
    "#seting the seed for tensorflow random numbers\n",
    "tf.set_random_seed(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# classes_name = []\n",
    "# files_name = []\n",
    "# for root, dirs, files in os.walk('Dataset1/Train'):  \n",
    "#     for name in dirs:\n",
    "#         classes_name.append(name)\n",
    "#     for name1 in files:\n",
    "#         files_name.append(name1)\n",
    "\n",
    "# print(len(classes_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ##### calculate  number of images\n",
    "# import os\n",
    "# classes_name_train = []\n",
    "# files_name_train = []\n",
    "# classes_name_test = []\n",
    "# files_name_test = []\n",
    "# for root, dirs, files in os.walk('Dataset1/Train'):  \n",
    "#     for name in dirs:\n",
    "#         classes_name_train.append(name)\n",
    "#     for name1 in files:\n",
    "#         files_name_train.append(name1)\n",
    "        \n",
    "# for root, dirs, files in os.walk('Data/Test'):  \n",
    "#     for name in dirs:\n",
    "#         classes_name_test.append(name)\n",
    "#     for name1 in files:\n",
    "#         files_name_test.append(name1)\n",
    "\n",
    "# no_training = len(files_name_train)\n",
    "# no_testing = len(files_name_test)\n",
    "        \n",
    "# print(len(classes_name_train))\n",
    "# print(len(files_name_train))\n",
    "# print(len(classes_name_test))\n",
    "# print(len(files_name_test))\n",
    "# number_classes = len(classes_name_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size = 8\n",
    "# n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_path = 'Dataset1/Train'\n",
    "# test_path = 'Data\\M2'\n",
    "# train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size = (224,224), classes = classes_name, batch_size = batch_size)\n",
    "# test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size = (224,224), classes = classes_name, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################### VGG19 ################# \n",
    "#################################################\n",
    "\n",
    "def VGG19(input_tensor=None, input_shape=None, pooling=None, classes=1000):\n",
    "    \n",
    "    # Determine proper input shape\n",
    "    if input_shape == None:\n",
    "        input_shape = (224,224,3)\n",
    "    \n",
    "    img_input = Input(input_shape)\n",
    "    \n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block21_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block21_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block21_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block22_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block22_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block22_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block23_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block23_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block23_conv3')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block23_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block23_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block24_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block24_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block24_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block24_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block24_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block25_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block25_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block25_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block25_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block25_pool')(x)\n",
    "\n",
    "\n",
    "    # Classification block\n",
    "    \n",
    "    x = Flatten(name='flatten2')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc21')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc22')(x)\n",
    "    x = Dense(classes, activation='softmax', name='predictions2')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg19')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg19_model = VGG19()\n",
    "vgg19_model.load_weights('vgg19_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "# vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### fine_tune vgg_face \n",
    "def convblock(cdim, nb, bits=3):\n",
    "    L = []\n",
    "    \n",
    "    for k in range(1,bits+1):\n",
    "        convname = 'conv'+str(nb)+'_'+str(k)\n",
    "        #L.append( Convolution2D(cdim, 3, 3, border_mode='same', activation='relu', name=convname) ) # Keras 1\n",
    "        L.append( Convolution2D(cdim, kernel_size=(3, 3), padding='same', activation='relu', name=convname) ) # Keras 2\n",
    "    \n",
    "    L.append( MaxPooling2D((2, 2), strides=(2, 2)) )\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_face_blank():\n",
    "    \n",
    "    withDO = True # no effect during evaluation but usefull for fine-tuning\n",
    "    \n",
    "    if True:\n",
    "        mdl = Sequential()\n",
    "        \n",
    "        # First layer is a dummy-permutation = Identity to specify input shape\n",
    "        mdl.add( Permute((1,2,3), input_shape=(224,224,3)) ) # WARNING : 0 is the sample dim\n",
    "\n",
    "        for l in convblock(64, 1, bits=2):\n",
    "            mdl.add(l)\n",
    "\n",
    "        for l in convblock(128, 2, bits=2):\n",
    "            mdl.add(l)\n",
    "        \n",
    "        for l in convblock(256, 3, bits=3):\n",
    "            mdl.add(l)\n",
    "            \n",
    "        for l in convblock(512, 4, bits=3):\n",
    "            mdl.add(l)\n",
    "            \n",
    "        for l in convblock(512, 5, bits=3):\n",
    "            mdl.add(l)\n",
    "        \n",
    "        #mdl.add( Convolution2D(4096, 7, 7, activation='relu', name='fc6') ) # Keras 1\n",
    "        mdl.add( Convolution2D(4096, kernel_size=(7, 7), activation='relu', name='fc6') ) # Keras 2\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "        #mdl.add( Convolution2D(4096, 1, 1, activation='relu', name='fc7') ) # Keras 1\n",
    "        mdl.add( Convolution2D(4096, kernel_size=(1, 1), activation='relu', name='fc7') ) # Keras 2\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "        #mdl.add( Convolution2D(2622, 1, 1, name='fc8') ) # Keras 1\n",
    "        mdl.add( Convolution2D(2622, kernel_size=(1, 1), activation='relu', name='fc8') ) # Keras 2\n",
    "        mdl.add( Flatten() )\n",
    "        mdl.add( Activation('softmax') )\n",
    "        \n",
    "        return mdl\n",
    "    \n",
    "    else:\n",
    "        # See following link for a version based on Keras functional API :\n",
    "        # gist.github.com/EncodeTS/6bbe8cb8bebad7a672f0d872561782d9\n",
    "        raise ValueError('not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "facemodel = vgg_face_blank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute_1 (Permute)          (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "fc6 (Conv2D)                 (None, 1, 1, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "fc7 (Conv2D)                 (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "fc8 (Conv2D)                 (None, 1, 1, 2622)        10742334  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2622)              0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2622)              0         \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "facemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_vggface = Sequential()\n",
    "for layer in facemodel.layers:\n",
    "    model_vggface.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "data = loadmat('vgg-face.mat', matlab_compatible=False, struct_as_record=False)\n",
    "l = data['layers']\n",
    "description = data['meta'][0,0].classes[0,0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_compare(kmodel):\n",
    "    kerasnames = [lr.name for lr in kmodel.layers]\n",
    "\n",
    "    # WARNING : important setting as 2 of the 4 axis have same size dimension\n",
    "    #prmt = (3,2,0,1) # INFO : for 'th' setting of 'dim_ordering'\n",
    "    prmt = (0,1,2,3) # INFO : for 'channels_last' setting of 'image_data_format'\n",
    "\n",
    "    for i in range(l.shape[1]):\n",
    "        matname = l[0,i][0,0].name[0]\n",
    "        mattype = l[0,i][0,0].type[0]\n",
    "        if matname in kerasnames:\n",
    "            kindex = kerasnames.index(matname)\n",
    "            print(matname, mattype)\n",
    "            print(l[0,i][0,0].weights[0,0].transpose(prmt).shape, l[0,i][0,0].weights[0,1].shape)\n",
    "            print(kmodel.layers[kindex].get_weights()[0].shape, kmodel.layers[kindex].get_weights()[1].shape)\n",
    "            print('------------------------------------------')\n",
    "        else:\n",
    "            print('MISSING : ', matname, mattype)\n",
    "            print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def copy_mat_to_keras(kmodel):\n",
    "\n",
    "    kerasnames = [lr.name for lr in kmodel.layers]\n",
    "\n",
    "    # WARNING : important setting as 2 of the 4 axis have same size dimension\n",
    "    #prmt = (3,2,0,1) # INFO : for 'th' setting of 'dim_ordering'\n",
    "    prmt = (0,1,2,3) # INFO : for 'channels_last' setting of 'image_data_format'\n",
    "\n",
    "    for i in range(l.shape[1]):\n",
    "        matname = l[0,i][0,0].name[0]\n",
    "        if matname in kerasnames:\n",
    "            kindex = kerasnames.index(matname)\n",
    "            #print matname\n",
    "            l_weights = l[0,i][0,0].weights[0,0]\n",
    "            l_bias = l[0,i][0,0].weights[0,1]\n",
    "            f_l_weights = l_weights.transpose(prmt)\n",
    "            #f_l_weights = np.flip(f_l_weights, 2) # INFO : for 'th' setting in dim_ordering\n",
    "            #f_l_weights = np.flip(f_l_weights, 3) # INFO : for 'th' setting in dim_ordering\n",
    "            assert (f_l_weights.shape == kmodel.layers[kindex].get_weights()[0].shape)\n",
    "            assert (l_bias.shape[1] == 1)\n",
    "            assert (l_bias[:,0].shape == kmodel.layers[kindex].get_weights()[1].shape)\n",
    "            assert (len(kmodel.layers[kindex].get_weights()) == 2)\n",
    "            kmodel.layers[kindex].set_weights([f_l_weights, l_bias[:,0]])\n",
    "            #print '------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "copy_mat_to_keras(model_vggface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "for layer in vgg19_model.layers:\n",
    "    model1.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,3): \n",
    "    model1.layers.pop()\n",
    "\n",
    "n = len(model1.layers)\n",
    "for idx, layer in enumerate(model1.layers):\n",
    "    if idx < (n-1): \n",
    "           layer.trainable = False \n",
    "    else:\n",
    "           layer.trainable = True\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "for layer in model_vggface.layers:\n",
    "    model2.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,6): \n",
    "    model2.layers.pop()\n",
    "n = len(model2.layers)\n",
    "for idx, layer in enumerate(model2.layers):\n",
    "    if idx < (n-1): \n",
    "           layer.trainable = False  \n",
    "    else:\n",
    "           layer.trainable = True            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stream_model(input_tensor=None, model1 = model1, model2 = model2,  input_shape=None, classes=2):\n",
    "    \n",
    "    # Determine proper input shape\n",
    "    if input_shape == None:\n",
    "        input_shape = (224,224,3)\n",
    "    \n",
    "    img_input = Input(input_shape)\n",
    "    \n",
    "    # Block 1\n",
    "    x1 = model1(img_input)\n",
    "    \n",
    "    # Block 2 \n",
    "    x2 = model2(img_input)   \n",
    "    merged = keras.layers.concatenate([x1, x2], axis=1)\n",
    "    \n",
    "    # Classification block\n",
    "#    out = Dense(classes, activation = 'linear', kernel_regularizer = regularizers.l2(0.001), )(merged)\n",
    "    out = Dense(classes, activation='softmax')(merged)\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "        \n",
    "    # Create model.\n",
    "    model = Model(inputs, out, name='stream_model')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = stream_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 1000)         20024384    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 2622)         117479232   input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3622)         0           sequential_3[1][0]               \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            7246        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 137,510,862\n",
      "Trainable params: 102,771,790\n",
      "Non-trainable params: 34,739,072\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(model.layers)\n",
    "for idx, layer in enumerate(model.layers):\n",
    "    if idx < (n-3): \n",
    "           layer.trainable = False  \n",
    "    else:\n",
    "           layer.trainable = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# opt = Adam(lr=0.0001, decay=10e-6)\n",
    "# loss = 'categorical_crossentropy'\n",
    "# #sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss= loss, optimizer= opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ### training    \n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# # Save check point\n",
    "# filepath = \"vgg19_vggface2.weights.best.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose =1, save_best_only = True, mode ='max')\n",
    "# callbacks_list= [checkpoint]\n",
    "#  # Fit the model\n",
    "# # model.fit(X,Y, validation_split=0.33, nb_epoch =150, batch_size =10, callbacks = callbacks_list, verbose =0)\n",
    "\n",
    "# history = model.fit_generator(train_batches, steps_per_epoch = int(no_training / batch_size), validation_data = test_batches, validation_steps = int(no_testing / batch_size), epochs = n_epochs, shuffle=True, callbacks = callbacks_list, verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"vgg19_vggface2.weights.best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.evaluate_generator(generator = test_batches, steps = int(no_testing / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'Dataset1\\M2'\n",
    "frame_files = os.listdir(path)\n",
    "frame_files = sorted(frame_files)\n",
    "#print(frame_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "frame_paths = [os.path.join(path, f) for f in frame_files]\n",
    "\n",
    "file = open(\"prediction_file.txt\",\"w\")\n",
    "file.close()\n",
    "\n",
    "for frame_path in frame_paths:\n",
    "#    print(frame_path[-11:-4])\n",
    "    \n",
    "    im = Image.open(frame_path) \n",
    "    im = im.resize((224,224))\n",
    "    imarr = np.array(im).astype(np.float32)\n",
    "    imarr = np.expand_dims(imarr, axis=0)        \n",
    "    proba = model.predict(imarr, verbose=0)\n",
    "    pred_cls = np.argmax(proba,axis=1)  \n",
    "    prob = proba[0][1] \n",
    "#     prob = round(proba[0][1],10)\n",
    "#    print(prob)\n",
    "    \n",
    "    file = open(\"prediction_file.txt\", \"a\")\n",
    "    file.writelines(\"%s,%f \\n\" % (frame_path[-11:-4], prob))\n",
    "    file.close()\n",
    "\n",
    "#     if np.max(proba) >= 0.700:\n",
    "#         plt.title('')\n",
    "#     else:\n",
    "#         plt.title('')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file1 = open(\"label_file.txt\",\"w\")\n",
    "# file1.close()\n",
    "\n",
    "# frame_paths = [os.path.join(path, f) for f in frame_files]\n",
    "# cnt = 1 \n",
    "# for frame_path in frame_paths:\n",
    "#     if cnt < 301:\n",
    "#         label = 1\n",
    "#     else: \n",
    "#         label = 0 \n",
    "#     file = open(\"label_file.txt\", \"a\")\n",
    "#     file.writelines(\"%s,%d \\n\" % (frame_path[-11:-4], label))\n",
    "#     file.close()\n",
    "#     cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # calculate AUC \n",
    "# import sys\n",
    "# import argparse\n",
    "# import matplotlib.pyplot as plt\n",
    "# from auroc import compute_auroc, read_file, read_merged_file\n",
    "\n",
    "\n",
    "# predict_file = 'test_results.txt'\n",
    "# label_file = 'labels.txt'\n",
    "\n",
    "# [predict, target] = read_file(predict_file, label_file)\n",
    "\n",
    "# [auc, roc] = compute_auroc(predict,target)\n",
    "\n",
    "# print('%0.7f' % (auc))\n",
    "\n",
    "# n = len(predict)\n",
    "\n",
    "# # This is for plotting\n",
    "# plt.plot(*zip(*roc), label='ROC curve')\n",
    "# plt.plot([0,1],      label='Random guess', linestyle='--', color='red')\n",
    "# plt.legend(loc=4)\n",
    "# plt.ylabel('TPR (True Positive Rate)')\n",
    "# plt.xlabel('FPR (False Positive Rate)')\n",
    "# plt.title('ROC Curve (AUROC : %7.3f)' % (auc))\n",
    "# plt.axis([0,1,0,1])\n",
    "# plt.grid()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
